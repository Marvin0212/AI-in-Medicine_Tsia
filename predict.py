# -*- coding: utf-8 -*-
"""Explore_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18G7sZ51hHhf7tbhx_jmexwXFlgJiK8mV
"""

# -*- coding: utf-8 -*-
"""

Skript testet das vortrainierte Modell


@author: Christoph Hoog Antink, Maurice Rohr
"""

import csv
import scipy.io as sio
import matplotlib.pyplot as plt
import numpy as np
import os
from typing import List, Tuple
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
import pickle

##preprocessing of data##########
def data_preprocessing(ecg_lead,zero_mean_loop):
  if zero_mean_loop ==2:# repeat array to fill 
        if ecg_lead.size<9000: 
          ecg_array_processed = np.array([])
          ecg_array_processed_part2 = np.zeros((9000,), dtype=int)
          #data gets looped till it has size of atleast 9000
          repetitions,remainder=divmod(9000,ecg_lead.size)
          repetitions+=1 
          for x in range(repetitions): 
            ecg_array_processed=np.concatenate((ecg_array_processed,ecg_lead))
          return ecg_array_processed[0:9000],ecg_array_processed_part2[0:9000]      
        if ecg_lead.size>9000:
          #first 9000 can be used unaltered
          ecg_array_processed=ecg_lead[0:9000]
          ecg_array_processed_part2 = np.array([])
          #data above 9000 gets looped till it has size of atleast 9000
          repetitions,remainder=divmod(9000,ecg_lead.size-9000)
          repetitions+=1 
          for x in range(repetitions): 
            ecg_array_processed_part2=np.concatenate((ecg_array_processed_part2,ecg_lead[9000:ecg_lead.size]))
          return ecg_array_processed[0:9000],ecg_array_processed_part2[0:9000]
        if ecg_lead.size==9000:
          ecg_array_processed=ecg_lead[0:9000]
          ecg_array_processed_part2 = np.zeros((9000,), dtype=int)
          return ecg_array_processed,ecg_array_processed_part2[0:9000]
  else: # zero or mean fill of array
        if zero_mean_loop == 0:
          ecg_array_processed = np.zeros((9000,), dtype=int)
          ecg_array_processed_part2 = np.zeros((10000,), dtype=int)
        if zero_mean_loop ==1:
          ecg_mean=np.mean(ecg_lead)   
          ecg_array_processed = np.empty([9000,])
          ecg_array_processed_part2 = np.empty([10000,])
          ecg_array_processed.fill(ecg_mean)
          ecg_array_processed_part2.fill(ecg_mean)
        if ecg_lead.size<9000:      
          ecg_array_processed[0:ecg_lead.size]=ecg_lead[0:ecg_lead.size]
          return ecg_array_processed,ecg_array_processed_part2[0:9000]      
        if ecg_lead.size>9000:
          ecg_array_processed=ecg_lead[0:9000]
          ecg_array_processed_part2[0:ecg_lead.size-9000]=ecg_lead[9000:ecg_lead.size]
          return ecg_array_processed,ecg_array_processed_part2[0:9000]
        if ecg_lead.size==9000:
          ecg_array_processed=ecg_lead[0:9000]
          return ecg_array_processed,ecg_array_processed_part2[0:9000]   


###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden
def predict_labels(ecg_leads : List[np.ndarray], fs : float, ecg_names : List[str], model_name : str='model.npy',is_binary_classifier : bool=False) -> List[Tuple[str,str]]:
    '''
    Parameters
    ----------
    model_name : str
        Dateiname des Models. In Code-Pfad
    ecg_leads : list of numpy-Arrays
        EKG-Signale.
    fs : float
        Sampling-Frequenz der Signale.
    ecg_names : list of str
        eindeutige Bezeichnung für jedes EKG-Signal.
    model_name : str
        Name des Models, kann verwendet werden um korrektes Model aus Ordner zu laden
    is_binary_classifier : bool
        Falls getrennte Modelle für F1 und Multi-Score trainiert werden, wird hier übergeben, 
        welches benutzt werden soll
    Returns
    -------
    predictions : list of tuples
        ecg_name und eure Diagnose
    '''

#------------------------------------------------------------------------------
    predictions = list()   
    #load pretrained scaler
    #std_slc = pickle.load(open('/content/drive/My Drive/scaler.pkl','rb'))
    std_slc = pickle.load(open('scaler.pkl','rb'))
    #load model
    #bad_model = keras.models.load_model('/content/drive/My Drive/bad_CNN_model')
    bad_model = keras.models.load_model('bad_CNN_model')
    #test_predictions_baseline = bad_model.predict(X_val,verbose=0)
    for idx,ecg_lead in enumerate(ecg_leads):
########preprocessing
        #loop array
        ecg_lead = ecg_lead.astype('float32')
        ecg_array_processed,ecg_array_processed_part2 = data_preprocessing(ecg_lead,2)  
        #clip data
        ecg_array_processed = np.clip(ecg_array_processed, -500, 500)
        ecg_array_processed_part2 = np.clip(ecg_array_processed, -500, 500)
        #standardize
        ecg_array_processed=ecg_array_processed.reshape(1, -1)
        ecg_array_processed_std = std_slc.transform(ecg_array_processed)
        ecg_array_processed_part2=ecg_array_processed_part2.reshape(1, -1) 
        ecg_array_processed_std_part_2 = std_slc.transform(ecg_array_processed_part2)
########make predictions       
        prediction = bad_model.predict(ecg_array_processed_std,verbose=0)
        prediction_part2 = bad_model.predict(ecg_array_processed_std_part_2,verbose=0)
        #only consider part one of prediction if array is shorter than 9000
        if ecg_lead.size>9000:
            predictions=(prediction[0][1]+prediction_part2[0][1])/2    
        if prediction[0][1] < 0.5:
            predictions.append((ecg_names[idx], 'N'))
        else:
            predictions.append((ecg_names[idx], 'A'))
        if ((idx+1) % 100)==0:
            print(str(idx+1) + "\t Dateien wurden verarbeitet.")          
#------------------------------------------------------------------------------    
    return predictions # Liste von Tupels im Format (ecg_name,label) - Muss unverändert bleiben!